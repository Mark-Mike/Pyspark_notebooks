{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/jalorenzo/SparkNotebookColab/blob/master/BDF_12_Exercises.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uL0HHBxQa1Hc"
   },
   "source": [
    "#00 - Configuration of Apache Spark on Collaboratory\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AcWXhOxia5yZ"
   },
   "source": [
    "###Installing Java, Spark, and Findspark\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "This code installs Apache Spark 3.0.1, Java 8, and [Findspark](https://github.com/minrk/findspark), a library that makes it easy for Python to find Spark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KsAfQ0CrgnWf"
   },
   "outputs": [],
   "source": [
    "!apt-get update\n",
    "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
    "!wget  http://apache.osuosl.org/spark/spark-3.3.1/spark-3.3.1-bin-hadoop3.tgz  \n",
    "!tar xf spark-3.3.1-bin-hadoop3.tgz  \n",
    "!rm spark-3.3.1-bin-hadoop3.tgz    \n",
    "!pip install -q findspark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "urlhmQ_ra_ba"
   },
   "source": [
    "### Set Environment Variables\n",
    "Set the locations where Spark and Java are installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "hiOoj3rUgnVx"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: cannot remove '/content/spark': No such file or directory\n",
      "ln: failed to create symbolic link '/content/spark': No such file or directory\n",
      "/content/spark/\n",
      "DRIVE_DATA=/content/gdrive/My Drive/Enseignement/2022-2023/ING3/HPDA/BigDataFrameworks/data/\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
    "os.environ[\"SPARK_HOME\"] = \"/content/spark/\"\n",
    "os.environ[\"DRIVE_DATA\"] = \"/content/gdrive/My Drive/Enseignement/2022-2023/ING3/HPDA/BigDataFrameworks/data/\"\n",
    "\n",
    "!rm /content/spark\n",
    "!ln -s /content/spark-3.3.1-bin-hadoop3 /content/spark\n",
    "!export SPARK_HOME=/content/spark\n",
    "!export PATH=$PATH:$SPARK_HOME/bin:$SPARK_HOME/sbin\n",
    "!echo $SPARK_HOME\n",
    "!env |grep  \"DRIVE_DATA\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2URH7tCHbDqf"
   },
   "source": [
    "### Start a SparkSession\n",
    "This will start a local Spark session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BDF_01_Introduction_to_Apache_Spark.ipynb\t  BDF_10_Spark_MLib.ipynb\n",
      "BDF_02_Basic_operations_on_Spark.ipynb\t\t  BDF_11_Graph_processing.ipynb\n",
      "BDF_03_Working_with_DataFrames.ipynb\t\t  BDF_12_Exercises.ipynb\n",
      "BDF_04_Operations_on_DataFrames.ipynb\t\t  LICENSE.md\n",
      "BDF_05_RDDs_Resilient_Distributed_Datasets.ipynb  README.md\n",
      "BDF_06_Persistence_and_Partitioning.ipynb\t  content\n",
      "BDF_07_Advanced_concepts.ipynb\t\t\t  data\n",
      "BDF_08_Running_Spark_on_a_cluster.ipynb\t\t  hadoop-2.7.3\n",
      "BDF_09_Spark_Streaming.ipynb\t\t\t  setup.py\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "n8JD51WVauRN"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.10.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/26 00:36:11 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "PySpark version 3.3.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2, 3]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!python -V\n",
    "\n",
    "#import findspark\n",
    "#findspark.init()\n",
    "\n",
    "import os\n",
    "os.environ[\"DRIVE_DATA\"] = \"./data/\"\n",
    "\n",
    "from pyspark import SparkContext\n",
    "sc = SparkContext.getOrCreate()\n",
    "\n",
    "# Example: shows the PySpark version\n",
    "print(\"PySpark version {0}\".format(sc.version))\n",
    "\n",
    "# Example: parallelise an array and show the 2 first elements\n",
    "sc.parallelize([2, 3, 4, 5, 6]).cache().take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "Ar81vEOHauP2"
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "# We create a SparkSession object (or we retrieve it if it is already created)\n",
    "spark = SparkSession \\\n",
    ".builder \\\n",
    ".appName(\"My application\") \\\n",
    ".master(\"local[4]\") \\\n",
    ".getOrCreate()\n",
    "#.config(\"spark.driver.memory\", \"15g\") \\\n",
    "# We get the SparkContext\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KBMAZitVauMT"
   },
   "outputs": [],
   "source": [
    "# Mount Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jajoV8LDbTCe"
   },
   "source": [
    "\n",
    "---\n",
    "\n",
    "\n",
    "# 12 - Exercises. Final assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "za4qzjHXyxcn"
   },
   "source": [
    "## Exercise 12.1\n",
    "\n",
    "Let us extract information from the cite75_99.txt and apat63_99.txt files. Write a script that performs the following operations:\n",
    "\n",
    "1. From the cite75_99.txt file, obtain the number of citations received by each patent. You must produce a DataFrame with the following format:\n",
    "\n",
    "| PatentNum | ncitations |\n",
    "|-----------|------------|\n",
    "| 3060453   |    3       |\n",
    "| 3390168   |    6       |\n",
    "| 3626542   |   18       | \n",
    "| 3611507   |    5       |\n",
    "| 3000113   |    4       |\n",
    "\n",
    "\n",
    "2. From the apat63_99.txt file, create a DataFrame to show the patent number, its country and the patent year, discarding the rest of fields in the file. The DataFrame produced must have the following format:\n",
    "\n",
    "|PatentNum |country|Year |\n",
    "|----------|-------|-----|\n",
    "| 3070801  | BE    | 1963| \n",
    "| 3070802  | US    | 1963| \n",
    "| 3070803  | US    | 1963| \n",
    "| 3070804  | US    | 1963| \n",
    "| 3070805  | US    | 1963|\n",
    "\n",
    " \n",
    "**Requirements**\n",
    "\n",
    " - Both DataFrames must be stored in Parquet format with gzip compression. Check the number of partitions of each DataFrame and the number of files gererated.\n",
    "\n",
    " - It is **strongly advised** to copy the files from your Drive to a temporal directory in the notebook virtual machine and unzip them there. This will reduce the execution times. See the cell below:\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading package lists... Done\n",
      "Building dependency tree... Done\n",
      "Reading state information... Done\n",
      "Suggested packages:\n",
      "  bzip2-doc\n",
      "The following NEW packages will be installed:\n",
      "  bzip2\n",
      "0 upgraded, 1 newly installed, 0 to remove and 0 not upgraded.\n",
      "Need to get 49.3 kB of archives.\n",
      "After this operation, 125 kB of additional disk space will be used.\n",
      "Get:1 http://deb.debian.org/debian bullseye/main amd64 bzip2 amd64 1.0.8-4 [49.3 kB]\n",
      "Fetched 49.3 kB in 1s (83.1 kB/s)\n",
      "debconf: delaying package configuration, since apt-utils is not installed\n",
      "Selecting previously unselected package bzip2.\n",
      "(Reading database ... 8860 files and directories currently installed.)\n",
      "Preparing to unpack .../bzip2_1.0.8-4_amd64.deb ...\n",
      "Unpacking bzip2 (1.0.8-4) ...\n",
      "Setting up bzip2 (1.0.8-4) ...\n"
     ]
    }
   ],
   "source": [
    "!apt-get install -y bzip2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "aV_M6xMlB9hP"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘tmp’: File exists\n",
      "mkdir: cannot create directory ‘./tmp/data/’: File exists\n",
      "apat63_99.txt.tar.bz2  cite75_99.txt.tar.bz2\n",
      "apat63_99.txt  cite75_99.txt\n"
     ]
    }
   ],
   "source": [
    "!mkdir tmp\n",
    "!mkdir ./tmp/data/\n",
    "!cp \"$DRIVE_DATA\"apat63_99.txt.tar.bz2 \"$DRIVE_DATA\"cite75_99.txt.tar.bz2 ./tmp/data\n",
    "#%cd ./tmp/data\n",
    "!ls ./tmp/data\n",
    "!tar -jxf ./tmp/data/apat63_99.txt.tar.bz2 -C ./tmp/data/\n",
    "!tar -jxf ./tmp/data/cite75_99.txt.tar.bz2 -C ./tmp/data/\n",
    "!rm ./tmp/data/*.tar.bz2\n",
    "!ls ./tmp/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+-----+-------+-------+-------+--------+-------+------+------+---+------+-----+--------+--------+-------+--------+--------+--------+--------+--------+--------+--------+\n",
      "|PATENT |GYEAR|GDATE|APPYEAR|COUNTRY|POSTATE|ASSIGNEE|ASSCODE|CLAIMS|NCLASS|CAT|SUBCAT|CMADE|CRECEIVE|RATIOCIT|GENERAL|ORIGINAL|FWDAPLAG|BCKGTLAG|SELFCTUB|SELFCTLB|SECDUPBD|SECDLWBD|\n",
      "+-------+-----+-----+-------+-------+-------+--------+-------+------+------+---+------+-----+--------+--------+-------+--------+--------+--------+--------+--------+--------+--------+\n",
      "|3070801|1963 |1096 |null   |BE     |null   |null    |1      |null  |269   |6  |69    |null |1       |null    |0.0    |null    |null    |null    |null    |null    |null    |null    |\n",
      "|3070802|1963 |1096 |null   |US     |TX     |null    |1      |null  |2     |6  |63    |null |0       |null    |null   |null    |null    |null    |null    |null    |null    |null    |\n",
      "|3070803|1963 |1096 |null   |US     |IL     |null    |1      |null  |2     |6  |63    |null |9       |null    |0.3704 |null    |null    |null    |null    |null    |null    |null    |\n",
      "|3070804|1963 |1096 |null   |US     |OH     |null    |1      |null  |2     |6  |63    |null |3       |null    |0.6667 |null    |null    |null    |null    |null    |null    |null    |\n",
      "|3070805|1963 |1096 |null   |US     |CA     |null    |1      |null  |2     |6  |63    |null |1       |null    |0.0    |null    |null    |null    |null    |null    |null    |null    |\n",
      "|3070806|1963 |1096 |null   |US     |PA     |null    |1      |null  |2     |6  |63    |null |0       |null    |null   |null    |null    |null    |null    |null    |null    |null    |\n",
      "|3070807|1963 |1096 |null   |US     |OH     |null    |1      |null  |623   |3  |39    |null |3       |null    |0.4444 |null    |null    |null    |null    |null    |null    |null    |\n",
      "|3070808|1963 |1096 |null   |US     |IA     |null    |1      |null  |623   |3  |39    |null |4       |null    |0.375  |null    |null    |null    |null    |null    |null    |null    |\n",
      "|3070809|1963 |1096 |null   |US     |AZ     |null    |1      |null  |4     |6  |65    |null |0       |null    |null   |null    |null    |null    |null    |null    |null    |null    |\n",
      "|3070810|1963 |1096 |null   |US     |IL     |null    |1      |null  |4     |6  |65    |null |3       |null    |0.4444 |null    |null    |null    |null    |null    |null    |null    |\n",
      "|3070811|1963 |1096 |null   |US     |CA     |null    |1      |null  |4     |6  |65    |null |8       |null    |0.0    |null    |null    |null    |null    |null    |null    |null    |\n",
      "|3070812|1963 |1096 |null   |US     |LA     |null    |1      |null  |4     |6  |65    |null |3       |null    |0.4444 |null    |null    |null    |null    |null    |null    |null    |\n",
      "|3070813|1963 |1096 |null   |US     |NY     |null    |1      |null  |5     |6  |65    |null |2       |null    |0.0    |null    |null    |null    |null    |null    |null    |null    |\n",
      "|3070814|1963 |1096 |null   |US     |MN     |null    |2      |null  |267   |5  |59    |null |2       |null    |0.5    |null    |null    |null    |null    |null    |null    |null    |\n",
      "|3070815|1963 |1096 |null   |US     |CO     |null    |1      |null  |7     |5  |59    |null |1       |null    |0.0    |null    |null    |null    |null    |null    |null    |null    |\n",
      "|3070816|1963 |1096 |null   |US     |OK     |null    |1      |null  |114   |5  |55    |null |4       |null    |0.0    |null    |null    |null    |null    |null    |null    |null    |\n",
      "|3070817|1963 |1096 |null   |US     |RI     |null    |2      |null  |114   |5  |55    |null |5       |null    |0.64   |null    |null    |null    |null    |null    |null    |null    |\n",
      "|3070818|1963 |1096 |null   |US     |IN     |null    |1      |null  |441   |6  |69    |null |4       |null    |0.625  |null    |null    |null    |null    |null    |null    |null    |\n",
      "|3070819|1963 |1096 |null   |US     |TN     |null    |4      |null  |12    |6  |63    |null |0       |null    |null   |null    |null    |null    |null    |null    |null    |null    |\n",
      "|3070820|1963 |1096 |null   |GB     |null   |null    |2      |null  |12    |6  |63    |null |0       |null    |null   |null    |null    |null    |null    |null    |null    |null    |\n",
      "+-------+-----+-----+-------+-------+-------+--------+-------+------+------+---+------+-----+--------+--------+-------+--------+--------+--------+--------+--------+--------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "apat63DF = spark.read.option(\"header\", \"true\").option(\"delimiter\", \",\").option(\"inferSchema\", \"true\").csv(\"./tmp/data/apat63_99.txt\")\n",
    "#apat63DF = spark.read.text(\"./tmp/data/apat63_99.txt\")\n",
    "#spark.createDataFrame(apat63DF, schema=)\n",
    "\n",
    "apat63DF.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- PATENT: integer (nullable = true)\n",
      " |-- GYEAR: integer (nullable = true)\n",
      " |-- GDATE: integer (nullable = true)\n",
      " |-- APPYEAR: integer (nullable = true)\n",
      " |-- COUNTRY: string (nullable = true)\n",
      " |-- POSTATE: string (nullable = true)\n",
      " |-- ASSIGNEE: integer (nullable = true)\n",
      " |-- ASSCODE: integer (nullable = true)\n",
      " |-- CLAIMS: integer (nullable = true)\n",
      " |-- NCLASS: integer (nullable = true)\n",
      " |-- CAT: integer (nullable = true)\n",
      " |-- SUBCAT: integer (nullable = true)\n",
      " |-- CMADE: integer (nullable = true)\n",
      " |-- CRECEIVE: integer (nullable = true)\n",
      " |-- RATIOCIT: double (nullable = true)\n",
      " |-- GENERAL: double (nullable = true)\n",
      " |-- ORIGINAL: double (nullable = true)\n",
      " |-- FWDAPLAG: double (nullable = true)\n",
      " |-- BCKGTLAG: double (nullable = true)\n",
      " |-- SELFCTUB: double (nullable = true)\n",
      " |-- SELFCTLB: double (nullable = true)\n",
      " |-- SECDUPBD: double (nullable = true)\n",
      " |-- SECDLWBD: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "apat63DF.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 85:>                                                         (0 + 2) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+\n",
      "|CITING |CITED  |\n",
      "+-------+-------+\n",
      "|3858241|956203 |\n",
      "|3858241|1324234|\n",
      "|3858241|3398406|\n",
      "|3858241|3557384|\n",
      "|3858241|3634889|\n",
      "|3858242|1515701|\n",
      "|3858242|3319261|\n",
      "|3858242|3668705|\n",
      "|3858242|3707004|\n",
      "|3858243|2949611|\n",
      "|3858243|3146465|\n",
      "|3858243|3156927|\n",
      "|3858243|3221341|\n",
      "|3858243|3574238|\n",
      "|3858243|3681785|\n",
      "|3858243|3684611|\n",
      "|3858244|14040  |\n",
      "|3858244|17445  |\n",
      "|3858244|2211676|\n",
      "|3858244|2635670|\n",
      "+-------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "cite75DF = spark.read.option(\"header\", \"true\").option(\"delimiter\", \",\").option(\"inferSchema\", \"true\").csv(\"./tmp/data/cite75_99.txt\")\n",
    "\n",
    "cite75DF.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- CITING: integer (nullable = true)\n",
      " |-- CITED: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cite75DF.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "newcite75DF = cite75DF.groupby('CITED').agg((cite75DF.CITED).alias('PatentNum'), F.count(cite75DF.CITED).alias('ncitations')).drop('CITED') #select((cite75DF.CITING).alias('PatentNum'), (cite75DF.CITED).alias('ncitations'))\n",
    "newapat63DF = apat63DF.select((apat63DF.PATENT).alias('PatentNum'), (apat63DF.COUNTRY).alias('country'), (apat63DF.GYEAR).alias('Year'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 120:>                                                        (0 + 2) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/20 11:13:33 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 120:============================>                            (1 + 1) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+\n",
      "|PatentNum|ncitations|\n",
      "+---------+----------+\n",
      "|  3060453|         3|\n",
      "|  3390168|         6|\n",
      "|  3626542|        18|\n",
      "|  3611507|         5|\n",
      "|  3000113|         4|\n",
      "|  3273281|         1|\n",
      "|  3550403|         2|\n",
      "|   228233|         1|\n",
      "|  3827399|         1|\n",
      "|  2622583|         1|\n",
      "|  3381752|        10|\n",
      "|  1035529|         1|\n",
      "|  2664273|         6|\n",
      "|  3289868|        16|\n",
      "|  3400790|         7|\n",
      "|  3618714|         8|\n",
      "|  3297130|         7|\n",
      "|  1715276|         4|\n",
      "|    50223|         1|\n",
      "|   685851|         1|\n",
      "+---------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "newcite75DF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 123:============================>                            (1 + 1) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+\n",
      "|PatentNum|ncitations|\n",
      "+---------+----------+\n",
      "|  3060453|         3|\n",
      "+---------+----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "newcite75DF.where(F.col(\"PatentNum\")=='3060453').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------+----+\n",
      "|PatentNum|country|Year|\n",
      "+---------+-------+----+\n",
      "|  3070801|     BE|1963|\n",
      "|  3070802|     US|1963|\n",
      "|  3070803|     US|1963|\n",
      "|  3070804|     US|1963|\n",
      "|  3070805|     US|1963|\n",
      "|  3070806|     US|1963|\n",
      "|  3070807|     US|1963|\n",
      "|  3070808|     US|1963|\n",
      "|  3070809|     US|1963|\n",
      "|  3070810|     US|1963|\n",
      "|  3070811|     US|1963|\n",
      "|  3070812|     US|1963|\n",
      "|  3070813|     US|1963|\n",
      "|  3070814|     US|1963|\n",
      "|  3070815|     US|1963|\n",
      "|  3070816|     US|1963|\n",
      "|  3070817|     US|1963|\n",
      "|  3070818|     US|1963|\n",
      "|  3070819|     US|1963|\n",
      "|  3070820|     GB|1963|\n",
      "+---------+-------+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "newapat63DF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -r ./tmp/data/newapat63DF.parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "newapat63DF.write.format(\"parquet\")\\\n",
    "    .mode(\"overwrite\")\\\n",
    "    .save(\"./tmp/data/newapat63DF.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -r ./tmp/data/newcite75DF.parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 128:>                                                        (0 + 2) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/20 11:15:36 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "newcite75DF.write.format(\"parquet\")\\\n",
    "    .mode(\"overwrite\")\\\n",
    "    .save(\"./tmp/data/newcite75DF.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newapat63DF.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 131:>                                                        (0 + 2) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/20 11:16:25 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 131:============================>                            (1 + 1) / 2]\r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newcite75DF.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apat63_99.txt  cite75_99.txt  newapat63DF.parquet  newcite75DF.parquet\n"
     ]
    }
   ],
   "source": [
    "!ls ./tmp/data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 16M\n",
      "drwxrwxrwx 1 1000 1000 4.0K Jan 20 11:15 .\n",
      "drwxrwxrwx 1 1000 1000 4.0K Jan 20 11:15 ..\n",
      "-rwxrwxrwx 1 1000 1000    8 Jan 20 11:15 ._SUCCESS.crc\n",
      "-rwxrwxrwx 1 1000 1000  60K Jan 20 11:15 .part-00000-4e3077c4-1fb5-4ecc-b8ab-5de2053d5e76-c000.snappy.parquet.crc\n",
      "-rwxrwxrwx 1 1000 1000  60K Jan 20 11:15 .part-00001-4e3077c4-1fb5-4ecc-b8ab-5de2053d5e76-c000.snappy.parquet.crc\n",
      "-rwxrwxrwx 1 1000 1000    0 Jan 20 11:15 _SUCCESS\n",
      "-rwxrwxrwx 1 1000 1000 7.5M Jan 20 11:15 part-00000-4e3077c4-1fb5-4ecc-b8ab-5de2053d5e76-c000.snappy.parquet\n",
      "-rwxrwxrwx 1 1000 1000 7.5M Jan 20 11:15 part-00001-4e3077c4-1fb5-4ecc-b8ab-5de2053d5e76-c000.snappy.parquet\n"
     ]
    }
   ],
   "source": [
    "!ls -alh ./tmp/data/newcite75DF.parquet # number of partitions : 2, number of files created : 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 14M\n",
      "drwxrwxrwx 1 1000 1000 4.0K Jan 20 11:15 .\n",
      "drwxrwxrwx 1 1000 1000 4.0K Jan 20 11:15 ..\n",
      "-rwxrwxrwx 1 1000 1000    8 Jan 20 11:15 ._SUCCESS.crc\n",
      "-rwxrwxrwx 1 1000 1000  56K Jan 20 11:14 .part-00000-ae88285f-4c08-418e-9c8b-e1e20b08c801-c000.snappy.parquet.crc\n",
      "-rwxrwxrwx 1 1000 1000  48K Jan 20 11:14 .part-00001-ae88285f-4c08-418e-9c8b-e1e20b08c801-c000.snappy.parquet.crc\n",
      "-rwxrwxrwx 1 1000 1000    0 Jan 20 11:15 _SUCCESS\n",
      "-rwxrwxrwx 1 1000 1000 7.0M Jan 20 11:14 part-00000-ae88285f-4c08-418e-9c8b-e1e20b08c801-c000.snappy.parquet\n",
      "-rwxrwxrwx 1 1000 1000 6.0M Jan 20 11:14 part-00001-ae88285f-4c08-418e-9c8b-e1e20b08c801-c000.snappy.parquet\n"
     ]
    }
   ],
   "source": [
    "!ls -alh ./tmp/data/newapat63DF.parquet # number of partitions : 2, number of files created : 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HF1_LXZEnzMn"
   },
   "source": [
    "## Exercise 12.2\n",
    "\n",
    "Write a code that, from the Parquet files created in the previous exercise, obtains for each country and for each year: the total number of patents, the total number of citations from those patents, the average number of citations and the maximum number of citations. Compute only those values in which there are any values in both files (*inner join*). In addition, each country must show its whole name, obtained from the *country_codes.txt* file. The final DataFrame must look like this one:\n",
    "\n",
    "\n",
    "|Country            |Year|PatentsNum |TotalCitations|AvgCitations      |MaxCitations|\n",
    "|-------------------|----|-----------|--------------|------------------|------------|\n",
    "|Algeria            |1963|2          |7             |3.5               |4           |\n",
    "|Algeria            |1968|1          |2             |2.0               |2           |\n",
    "|Algeria            |1970|1          |2             |2.0               |2           |\n",
    "|Algeria            |1972|1          |1             |1.0               |1           |\n",
    "|Algeria            |1977|1          |2             |2.0               |2           |\n",
    "|Andorra            |1987|1          |3             |3.0               |3           |\n",
    "|Andorra            |1993|1          |1             |1.0               |1           |\n",
    "|Andorra            |1998|1          |1             |1.0               |1           |\n",
    "|Antigua and Barbuda|1978|1          |6             |6.0               |6           |\n",
    "|Antigua and Barbuda|1979|1          |14            |14.0              |14          |\n",
    "|Antigua and Barbuda|1991|1          |8             |8.0               |8           |\n",
    "|Antigua and Barbuda|1994|1          |19            |19.0              |19          |\n",
    "|Antigua and Barbuda|1995|2          |12            |6.0               |11          |\n",
    "|Antigua and Barbuda|1996|2          |3             |1.5               |2           |\n",
    "|Argentina          |1963|14         |35            |2.5               |7           |\n",
    "|Argentina          |1964|20         |60            |3.0               |8           |\n",
    "|Argentina          |1965|10         |35            |3.5               |10          |\n",
    "|Argentina          |1966|16         |44            |2.75              |9           |\n",
    "|Argentina          |1967|13         |60            |4.615384615384615 |14          |\n",
    "\n",
    "**Requirements**\n",
    "\n",
    "- The output DataFrame must be saved in a single CSV file, with a header and without any compression.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[PatentNum: int, ncitations: bigint]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ncDF = spark.read\\\n",
    "            .format(\"parquet\")\\\n",
    "            .option(\"mode\", \"FAILFAST\")\\\n",
    "            .load(\"./tmp/data/newcite75DF.parquet\")\n",
    "ncDF.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 61:>                                                         (0 + 2) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+\n",
      "|PatentNum|ncitations|\n",
      "+---------+----------+\n",
      "|        1|         2|\n",
      "|       13|         2|\n",
      "|       24|         1|\n",
      "|       29|         1|\n",
      "|       31|         2|\n",
      "|       42|         3|\n",
      "|       51|         1|\n",
      "|       52|         1|\n",
      "|       53|         1|\n",
      "|       84|         1|\n",
      "|       87|         1|\n",
      "|       92|         1|\n",
      "|      105|         1|\n",
      "|      107|         2|\n",
      "|      115|         1|\n",
      "|      168|         1|\n",
      "|      175|         1|\n",
      "|      178|         1|\n",
      "|      179|         1|\n",
      "|      186|         1|\n",
      "+---------+----------+\n",
      "only showing top 20 rows\n",
      "\n",
      "root\n",
      " |-- PatentNum: integer (nullable = true)\n",
      " |-- ncitations: long (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "ncDF.orderBy('PatentNum').show()\n",
    "ncDF.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[PatentNum: int, country: string, Year: int]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "naDF = spark.read\\\n",
    "            .format(\"parquet\")\\\n",
    "            .option(\"mode\", \"FAILFAST\")\\\n",
    "            .load(\"./tmp/data/newapat63DF.parquet\")\n",
    "naDF.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------+----+\n",
      "|PatentNum|country|Year|\n",
      "+---------+-------+----+\n",
      "|  3104211|     MA|1963|\n",
      "|  3087224|     MA|1963|\n",
      "|  3072682|     MA|1963|\n",
      "|  3120389|     MA|1964|\n",
      "|  3153481|     MA|1964|\n",
      "|  3121441|     MA|1964|\n",
      "|  3195481|     MA|1965|\n",
      "|  3172809|     MA|1965|\n",
      "|  3192085|     MA|1965|\n",
      "|  3171602|     MA|1965|\n",
      "|  3180877|     MA|1965|\n",
      "|  3191938|     MA|1965|\n",
      "|  3231275|     MA|1966|\n",
      "|  3254745|     MA|1966|\n",
      "|  3233363|     MA|1966|\n",
      "|  3281102|     MA|1966|\n",
      "|  3229648|     MA|1966|\n",
      "|  3284304|     MA|1966|\n",
      "|  3337956|     MA|1967|\n",
      "|  3342406|     MA|1967|\n",
      "+---------+-------+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "naDF.orderBy('country', 'Year').where(F.col(\"country\")=='MA').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------+----+\n",
      "|PatentNum|country|Year|\n",
      "+---------+-------+----+\n",
      "|  3070801|     BE|1963|\n",
      "|  3070802|     US|1963|\n",
      "|  3070803|     US|1963|\n",
      "|  3070804|     US|1963|\n",
      "|  3070805|     US|1963|\n",
      "|  3070806|     US|1963|\n",
      "|  3070807|     US|1963|\n",
      "|  3070808|     US|1963|\n",
      "|  3070809|     US|1963|\n",
      "|  3070810|     US|1963|\n",
      "|  3070811|     US|1963|\n",
      "|  3070812|     US|1963|\n",
      "|  3070813|     US|1963|\n",
      "|  3070814|     US|1963|\n",
      "|  3070815|     US|1963|\n",
      "|  3070816|     US|1963|\n",
      "|  3070817|     US|1963|\n",
      "|  3070818|     US|1963|\n",
      "|  3070819|     US|1963|\n",
      "|  3070820|     GB|1963|\n",
      "+---------+-------+----+\n",
      "only showing top 20 rows\n",
      "\n",
      "root\n",
      " |-- PatentNum: integer (nullable = true)\n",
      " |-- country: string (nullable = true)\n",
      " |-- Year: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "naDF.show()\n",
    "naDF.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StructField, StringType\n",
    "import os\n",
    "os.environ[\"DRIVE_DATA\"] = \"./data/\"\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"short\",StringType(),True),\n",
    "    StructField(\"full\",StringType(),True)\n",
    "])\n",
    "\n",
    "country_codes = spark.read.option(\"delimiter\", \"\\t\").csv(os.environ['DRIVE_DATA'] + 'country_codes.txt', schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------------------+\n",
      "|short|               full|\n",
      "+-----+-------------------+\n",
      "|   AF|        Afghanistan|\n",
      "|   AX|      Aland Islands|\n",
      "|   AL|            Albania|\n",
      "|   DZ|            Algeria|\n",
      "|   AS|     American Samoa|\n",
      "|   AD|            Andorra|\n",
      "|   AO|             Angola|\n",
      "|   AI|           Anguilla|\n",
      "|   AQ|         Antarctica|\n",
      "|   AG|Antigua and Barbuda|\n",
      "|   AR|          Argentina|\n",
      "|   AM|            Armenia|\n",
      "|   AW|              Aruba|\n",
      "|   AC|   Ascension Island|\n",
      "|   AU|          Australia|\n",
      "|   AT|            Austria|\n",
      "|   AZ|         Azerbaijan|\n",
      "|   BS|            Bahamas|\n",
      "|   BH|            Bahrain|\n",
      "|   BD|         Bangladesh|\n",
      "+-----+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "country_codes.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 12:>                                                         (0 + 2) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+----+---------+\n",
      "|            country|Year|PatentNum|\n",
      "+-------------------+----+---------+\n",
      "|            Albania|1999|  5992357|\n",
      "|            Algeria|1963|  3091754|\n",
      "|            Algeria|1963|  3113948|\n",
      "|            Algeria|1963|  3070963|\n",
      "|            Algeria|1965|  3208073|\n",
      "|            Algeria|1965|  3186382|\n",
      "|            Algeria|1968|  3393271|\n",
      "|            Algeria|1970|  3550376|\n",
      "|            Algeria|1972|  3649173|\n",
      "|            Algeria|1977|  4057649|\n",
      "|            Algeria|1998|  5849771|\n",
      "|            Andorra|1987|  4688621|\n",
      "|            Andorra|1993|  5193231|\n",
      "|            Andorra|1995|  5478082|\n",
      "|            Andorra|1998|  5785566|\n",
      "|            Andorra|1998|  5765303|\n",
      "|            Andorra|1999|  5894770|\n",
      "|           Anguilla|1998|  5765334|\n",
      "|Antigua and Barbuda|1978|  4126850|\n",
      "|Antigua and Barbuda|1979|  4172981|\n",
      "+-------------------+----+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "#, F.count(F.col(\"PatentNum\"))\n",
    "#naDF.join(country_codes, naDF.country == country_codes.short).select(F.col(\"full\").alias(\"country\"), F.col(\"Year\"), F.col(\"PatentNum\")).groupby('Year', 'country').agg({'PatentNum':'count'}).show()#.groupby('Year', 'country').count().where(F.col(\"country\")=='Argentina').show()\n",
    "newnaDF = naDF.join(country_codes, naDF.country == country_codes.short, \"inner\").select(F.col(\"full\").alias(\"country\"), F.col(\"Year\"), F.col(\"PatentNum\").alias('PatentNum'))\n",
    "newnaDF.orderBy('country', 'Year').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 14:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+\n",
      "|PatentNum|ncitations|\n",
      "+---------+----------+\n",
      "|  3060453|         3|\n",
      "+---------+----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "ncDF.where(F.col(\"PatentNum\")=='3060453').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+\n",
      "|PatentNum|ncitations|\n",
      "+---------+----------+\n",
      "|  3060453|         3|\n",
      "|  3390168|         6|\n",
      "|  3626542|        18|\n",
      "|  3611507|         5|\n",
      "|  3000113|         4|\n",
      "|  3273281|         1|\n",
      "|  3550403|         2|\n",
      "|   228233|         1|\n",
      "|  3827399|         1|\n",
      "|  2622583|         1|\n",
      "|  3381752|        10|\n",
      "|  1035529|         1|\n",
      "|  2664273|         6|\n",
      "|  3289868|        16|\n",
      "|  3400790|         7|\n",
      "|  3618714|         8|\n",
      "|  3297130|         7|\n",
      "|  1715276|         4|\n",
      "|    50223|         1|\n",
      "|   685851|         1|\n",
      "+---------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ncDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 27:>                                                         (0 + 2) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------------------+----+----------+\n",
      "|PatentNum|            country|Year|ncitations|\n",
      "+---------+-------------------+----+----------+\n",
      "|  3091754|            Algeria|1963|         4|\n",
      "|  3070963|            Algeria|1963|         3|\n",
      "|  3393271|            Algeria|1968|         2|\n",
      "|  3550376|            Algeria|1970|         2|\n",
      "|  3649173|            Algeria|1972|         1|\n",
      "|  4057649|            Algeria|1977|         2|\n",
      "|  4688621|            Andorra|1987|         3|\n",
      "|  5193231|            Andorra|1993|         1|\n",
      "|  5765303|            Andorra|1998|         1|\n",
      "|  4126850|Antigua and Barbuda|1978|         6|\n",
      "|  4172981|Antigua and Barbuda|1979|        14|\n",
      "|  5013035|Antigua and Barbuda|1991|         8|\n",
      "|  5345071|Antigua and Barbuda|1994|        19|\n",
      "|  5472566|Antigua and Barbuda|1995|         1|\n",
      "|  5457307|Antigua and Barbuda|1995|        11|\n",
      "|  5525786|Antigua and Barbuda|1996|         2|\n",
      "|  5536941|Antigua and Barbuda|1996|         1|\n",
      "|  3085146|          Argentina|1963|         2|\n",
      "|  3113990|          Argentina|1963|         2|\n",
      "|  3096233|          Argentina|1963|         7|\n",
      "+---------+-------------------+----+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "gf = newnaDF.join(ncDF, 'PatentNum', 'inner').orderBy('country', 'Year')\n",
    "gf.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 43:>                                                         (0 + 2) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/20 15:30:08 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "23/01/20 15:30:08 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 43:=============================>                            (1 + 1) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+----+----------+--------------+-----------------+------------+\n",
      "|            country|Year|PatentsNum|totalCitations|     avgCitations|maxCitations|\n",
      "+-------------------+----+----------+--------------+-----------------+------------+\n",
      "|            Algeria|1963|         2|             7|              3.5|           4|\n",
      "|            Algeria|1968|         1|             2|              2.0|           2|\n",
      "|            Algeria|1970|         1|             2|              2.0|           2|\n",
      "|            Algeria|1972|         1|             1|              1.0|           1|\n",
      "|            Algeria|1977|         1|             2|              2.0|           2|\n",
      "|            Andorra|1987|         1|             3|              3.0|           3|\n",
      "|            Andorra|1993|         1|             1|              1.0|           1|\n",
      "|            Andorra|1998|         1|             1|              1.0|           1|\n",
      "|Antigua and Barbuda|1978|         1|             6|              6.0|           6|\n",
      "|Antigua and Barbuda|1979|         1|            14|             14.0|          14|\n",
      "|Antigua and Barbuda|1991|         1|             8|              8.0|           8|\n",
      "|Antigua and Barbuda|1994|         1|            19|             19.0|          19|\n",
      "|Antigua and Barbuda|1995|         2|            12|              6.0|          11|\n",
      "|Antigua and Barbuda|1996|         2|             3|              1.5|           2|\n",
      "|          Argentina|1963|        14|            35|              2.5|           7|\n",
      "|          Argentina|1964|        20|            60|              3.0|           8|\n",
      "|          Argentina|1965|        10|            35|              3.5|          10|\n",
      "|          Argentina|1966|        16|            44|             2.75|           9|\n",
      "|          Argentina|1967|        13|            60|4.615384615384615|          14|\n",
      "|          Argentina|1968|        14|            80|5.714285714285714|          21|\n",
      "+-------------------+----+----------+--------------+-----------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#newgf = gf.groupby('country', 'Year').agg({'PatentNum':'count', 'ncitations': 'count', 'ncitations': 'avg'}).select(F.col('country'), F.col('Year'), F.col('count(ncitations)').alias('totalCitations')) #.agg({'': ''}).show() #orderBy('country','Year').show()\n",
    "#newgf.show()\n",
    "newgf = gf.groupby('country', 'Year').agg(F.count('PatentNum').alias('PatentsNum'), F.sum('ncitations').alias('totalCitations'), F.avg('ncitations').alias('avgCitations'), F.max('ncitations').alias('maxCitations')) #.select(F.col('country'), F.col('Year'), F.col('count(ncitations)').alias('totalCitations')) #.agg({'': ''}).show() #By('country','Year').show()\n",
    "newgf.orderBy('country','Year').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 56:=============================>                            (1 + 1) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+----------+--------------+------------------+------------+\n",
      "|country|Year|PatentsNum|totalCitations|      avgCitations|maxCitations|\n",
      "+-------+----+----------+--------------+------------------+------------+\n",
      "|Morocco|1963|         2|             2|               1.0|           1|\n",
      "|Morocco|1965|         4|            10|               2.5|           4|\n",
      "|Morocco|1966|         3|            10|3.3333333333333335|           5|\n",
      "|Morocco|1967|         2|            11|               5.5|          10|\n",
      "|Morocco|1968|         3|            22| 7.333333333333333|           9|\n",
      "|Morocco|1970|         2|             9|               4.5|           8|\n",
      "|Morocco|1972|         2|            22|              11.0|          14|\n",
      "|Morocco|1973|         2|             7|               3.5|           4|\n",
      "|Morocco|1977|         5|            36|               7.2|          10|\n",
      "|Morocco|1983|         1|             3|               3.0|           3|\n",
      "|Morocco|1984|         2|            13|               6.5|           7|\n",
      "|Morocco|1985|         1|            24|              24.0|          24|\n",
      "|Morocco|1988|         2|             8|               4.0|           7|\n",
      "|Morocco|1989|         2|            11|               5.5|           9|\n",
      "|Morocco|1991|         1|             1|               1.0|           1|\n",
      "|Morocco|1993|         1|             3|               3.0|           3|\n",
      "+-------+----+----------+--------------+------------------+------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "newgf.orderBy('country','Year').where(F.col(\"country\")=='Morocco').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2530"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newgf.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wT3WU-1IwOPD"
   },
   "source": [
    "## Exercise 12.3\n",
    "\n",
    "From the apat63_99.txt file, obtain the number of patents per country and year **using RDDs** (do not use DataFrames). The resulting RDD must be a key/value RDD in which the key is a country and the value a list of tuples. Each tuple will be composed of a year and the number of patents of the country during that year. In addition, the resulting RDD must be sorted by  the country code and, for each country, values must be sorted by year.\n",
    "\n",
    "Example of output key/value entry:\n",
    "\n",
    "    (u'PA', [(u'1963', 2), (u'1964', 2), (u'1965', 1), (u'1966', 1), (u'1970', 1), (u'1971', 1), (u'1972', 6), (u'1974', 3), (u'1975', 5), (u'1976', 3), (u'1977', 2), (u'1978', 2), (u'1980', 2), (u'1982', 1), (u'1983', 1), (u'1985', 2), (u'1986', 1), (u'1987', 2), (u'1988', 1), (u'1990', 1), (u'1991', 2), (u'1993', 1), (u'1995', 1), (u'1996', 1), (u'1999', 1)])\n",
    "\n",
    "**Requirements:**\n",
    "\n",
    "- You must remove the double quotation marks from the country code.\n",
    "- Use 8 partitions to read the apat63_99.txt.bz2 file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'naDF' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[88], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mnaDF\u001b[49m\u001b[38;5;241m.\u001b[39mshow()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'naDF' is not defined"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------+----+\n",
      "|PatentNum|country|Year|\n",
      "+---------+-------+----+\n",
      "|  3070801|     BE|1963|\n",
      "|  3070802|     US|1963|\n",
      "|  3070803|     US|1963|\n",
      "|  3070804|     US|1963|\n",
      "|  3070805|     US|1963|\n",
      "|  3070806|     US|1963|\n",
      "|  3070807|     US|1963|\n",
      "|  3070808|     US|1963|\n",
      "|  3070809|     US|1963|\n",
      "|  3070810|     US|1963|\n",
      "|  3070811|     US|1963|\n",
      "|  3070812|     US|1963|\n",
      "|  3070813|     US|1963|\n",
      "|  3070814|     US|1963|\n",
      "|  3070815|     US|1963|\n",
      "|  3070816|     US|1963|\n",
      "|  3070817|     US|1963|\n",
      "|  3070818|     US|1963|\n",
      "|  3070819|     US|1963|\n",
      "|  3070820|     GB|1963|\n",
      "+---------+-------+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "naDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "naDF = naDF.rdd.repartition(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "naDF.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "rdd_apat = sc.textFile(os.environ['DRIVE_DATA'] + 'apat63_99.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd_apat.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd_apat = rdd_apat.repartition(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd_apat.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MapPartitionsRDD[135] at coalesce at NativeMethodAccessorImpl.java:0"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd_apat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2923923"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd_apat.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['3070820,1963,1096,,\"GB\",\"\",,2,,12,6,63,,0,,,,,,,,,',\n",
       " '3070821,1963,1096,,\"US\",\"IL\",,2,,15,6,69,,1,,0,,,,,,,',\n",
       " '3070822,1963,1096,,\"US\",\"NY\",,2,,401,1,12,,4,,0.375,,,,,,,']"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd_apat.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3070820,1963,1096,,\"GB\",\"\",,2,,12,6,63,,0,,,,,,,,,'"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd_apat.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "newdata = rdd_apat.map(lambda line: line.split(\",\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['3070820',\n",
       "  '1963',\n",
       "  '1096',\n",
       "  '',\n",
       "  '\"GB\"',\n",
       "  '\"\"',\n",
       "  '',\n",
       "  '2',\n",
       "  '',\n",
       "  '12',\n",
       "  '6',\n",
       "  '63',\n",
       "  '',\n",
       "  '0',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  ''],\n",
       " ['3070821',\n",
       "  '1963',\n",
       "  '1096',\n",
       "  '',\n",
       "  '\"US\"',\n",
       "  '\"IL\"',\n",
       "  '',\n",
       "  '2',\n",
       "  '',\n",
       "  '15',\n",
       "  '6',\n",
       "  '69',\n",
       "  '',\n",
       "  '1',\n",
       "  '',\n",
       "  '0',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '']]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newdata.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuples = newdata.map(lambda row: (row[0], row[1], row[4].replace('\"', '')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('3070820', '1963', 'GB'),\n",
       " ('3070821', '1963', 'US'),\n",
       " ('3070822', '1963', 'US'),\n",
       " ('3070823', '1963', 'US'),\n",
       " ('3070824', '1963', 'US')]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuples.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('CH', <pyspark.resultiterable.ResultIterable at 0x7f33be754a60>),\n",
       " ('NO', <pyspark.resultiterable.ResultIterable at 0x7f33cce17970>),\n",
       " ('LI', <pyspark.resultiterable.ResultIterable at 0x7f33ccad78b0>)]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_tuples = tuples.groupBy(lambda x: x[2])\n",
    "grouped_tuples.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('1963', 5)]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "lst = [('3070820', '1963', 'GB'),\n",
    " ('3070821', '1963', 'US'),\n",
    " ('3070822', '1963', 'US'),\n",
    " ('3070823', '1963', 'US'),\n",
    " ('3070824', '1963', 'US')]\n",
    "groupedbycolumn = 1\n",
    "list(pd.DataFrame(lst).groupby(groupedbycolumn).agg(lambda x: len(x)).drop(len(lst[0])-1, axis=1).itertuples(name=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    import pandas as pd\n",
    "    groupedbycolumn = 1\n",
    "    # groupby date, and drop the additional column:\n",
    "    out = pd.DataFrame(x).groupby(groupedbycolumn).agg(lambda x: len(x)).drop(2, axis=1)\n",
    "    return list(out.itertuples(name=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_apat = grouped_tuples.mapValues(f) #.map(lambda x: (x[0], x[1].map(lambda x: x[0]))).take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('PA',\n",
       "  [('1963', 2),\n",
       "   ('1964', 2),\n",
       "   ('1965', 1),\n",
       "   ('1966', 1),\n",
       "   ('1970', 1),\n",
       "   ('1971', 1),\n",
       "   ('1972', 6),\n",
       "   ('1974', 3),\n",
       "   ('1975', 5),\n",
       "   ('1976', 3),\n",
       "   ('1977', 2),\n",
       "   ('1978', 2),\n",
       "   ('1980', 2),\n",
       "   ('1982', 1),\n",
       "   ('1983', 1),\n",
       "   ('1985', 2),\n",
       "   ('1986', 1),\n",
       "   ('1987', 2),\n",
       "   ('1988', 1),\n",
       "   ('1990', 1),\n",
       "   ('1991', 2),\n",
       "   ('1993', 1),\n",
       "   ('1995', 1),\n",
       "   ('1996', 1),\n",
       "   ('1999', 1)])]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_apat.filter(lambda x: x[0] == 'PA').collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g0LiWoc4VQdh"
   },
   "source": [
    "## Exercise 12.4\n",
    "\n",
    "From the Parquet files created in Exercise 12.1, create a DataFrame that gives the patent or patents with the higher number of citations per country and year, as well as the average of the number of citations per country and year, and the difference between the maximum and the average values. The resulting DataFrame should look like this:\n",
    "\n",
    "\n",
    "|Country|Year|PatentNum|max  |average       |diff              |\n",
    "|-------|----|---------|-----|--------------|------------------|\n",
    "|AD     |1987|4688621  |3    |3.0           |0.0               |\n",
    "|AD     |1993|5193231  |1    |1.0           |0.0               |\n",
    "|AD     |1998|5765303  |1    |1.0           |0.0               |\n",
    "|AE     |1984|4482959  |5    |5.0           |0.0               |\n",
    "|AE     |1985|4554981  |14   |14.0          |0.0               |\n",
    "|AE     |1987|4663181  |3    |3.0           |0.0               |\n",
    "|AE     |1989|4805221  |7    |5.0           |2.0               |\n",
    "|AE     |1990|4909321  |2    |2.0           |0.0               |\n",
    "|AE     |1991|5004552  |3    |2.0           |1.0               |\n",
    "|AE     |1992|5104556  |4    |4.0           |0.0               |\n",
    "|AE     |1993|5181569  |8    |8.0           |0.0               |\n",
    "|AE     |1996|5580125  |1    |1.0           |0.0               |\n",
    "|AG     |1978|4126850  |6    |6.0           |0.0               |\n",
    "|AG     |1979|4172981  |14   |14.0          |0.0               |\n",
    "|AG     |1991|5013035  |8    |8.0           |0.0               |\n",
    "|AG     |1994|5345071  |19   |19.0          |0.0               |\n",
    "|AG     |1995|5457307  |11   |6.0           |5.0               |\n",
    "|AG     |1996|5525786  |2    |1.5           |0.5               |\n",
    "\n",
    "**Requirements:**\n",
    "\n",
    "- The DataFrame must be sorted by country code and year.\n",
    "- Do **NOT** replace the country code by its whole name.\n",
    "- The output must be saved as a single CSV file, with a header and without any compression.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[PatentNum: int, ncitations: bigint]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nciteDF = spark.read\\\n",
    "            .format(\"parquet\")\\\n",
    "            .option(\"mode\", \"FAILFAST\")\\\n",
    "            .load(\"./tmp/data/newcite75DF.parquet\")\n",
    "nciteDF.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[PatentNum: int, country: string, Year: int]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newapatDF = spark.read\\\n",
    "            .format(\"parquet\")\\\n",
    "            .option(\"mode\", \"FAILFAST\")\\\n",
    "            .load(\"./tmp/data/newapat63DF.parquet\")\n",
    "newapatDF.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 3:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+\n",
      "|PatentNum|ncitations|\n",
      "+---------+----------+\n",
      "|  3060453|         3|\n",
      "|  3390168|         6|\n",
      "|  3626542|        18|\n",
      "|  3611507|         5|\n",
      "|  3000113|         4|\n",
      "+---------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "nciteDF.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 4:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------+----+\n",
      "|PatentNum|country|Year|\n",
      "+---------+-------+----+\n",
      "|  3070801|     BE|1963|\n",
      "|  3070802|     US|1963|\n",
      "|  3070803|     US|1963|\n",
      "|  3070804|     US|1963|\n",
      "|  3070805|     US|1963|\n",
      "+---------+-------+----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "newapatDF.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[country: string, Year: int, PatentNum: int, maxCitations: bigint, avgCitations: double, diffCitations: double]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[Year: int, country: string, PatentNum: int, maxCitations: bigint, avgCitations: double, diffCitations: double]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "output = newapatDF.join(nciteDF, 'PatentNum', 'inner').groupby('Year').agg(F.first('PatentNum').alias('PatentNum'), F.max('ncitations').alias('maxCitations'), F.avg('ncitations').alias('avgCitations')).orderBy(['country']).withColumn('diffCitations', F.col('maxCitations')-F.col('avgCitations'))\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 169:============================>                            (1 + 1) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+---------+------------+------------+-------------+\n",
      "|country|Year|PatentNum|maxCitations|avgCitations|diffCitations|\n",
      "+-------+----+---------+------------+------------+-------------+\n",
      "|     AD|1987|  4688621|           3|         3.0|          0.0|\n",
      "|     AD|1998|  5765303|           1|         1.0|          0.0|\n",
      "|     AD|1993|  5193231|           1|         1.0|          0.0|\n",
      "|     AE|1993|  5181569|           8|         8.0|          0.0|\n",
      "|     AE|1992|  5104556|           4|         4.0|          0.0|\n",
      "|     AE|1990|  4909321|           2|         2.0|          0.0|\n",
      "|     AE|1996|  5580125|           1|         1.0|          0.0|\n",
      "|     AE|1991|  4997041|           3|         2.0|          1.0|\n",
      "|     AE|1987|  4663181|           3|         3.0|          0.0|\n",
      "|     AE|1984|  4482959|           5|         5.0|          0.0|\n",
      "|     AE|1989|  4805221|           7|         5.0|          2.0|\n",
      "|     AE|1985|  4554981|          14|        14.0|          0.0|\n",
      "|     AG|1995|  5457307|          11|         6.0|          5.0|\n",
      "|     AG|1979|  4172981|          14|        14.0|          0.0|\n",
      "|     AG|1978|  4126850|           6|         6.0|          0.0|\n",
      "|     AG|1991|  5013035|           8|         8.0|          0.0|\n",
      "|     AG|1994|  5345071|          19|        19.0|          0.0|\n",
      "|     AG|1996|  5525786|           2|         1.5|          0.5|\n",
      "|     AM|1995|  5382341|           2|         2.0|          0.0|\n",
      "|     AN|1979|  4165701|           1|         1.0|          0.0|\n",
      "+-------+----+---------+------------+------------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "output.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "output.write.option(\"header\",True).csv('./out/output_12-4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ektPyLWzaImT"
   },
   "source": [
    "## Exercise 12.5\n",
    "\n",
    "From the Parquet file with the (PatentNum,Country,Year) information from Exercise 12.1, create a DataFrame that shows the number of patents associated to each country per decade (understanding as a *decade* the years from 0 to 9; e.g. from 1970 to 1979). In addition, the DataFrame must show the increase or decrease of the number of patents per country and decade with respect to the previous decade. The resulting DataFrame must look like this:\n",
    "\n",
    "|Country|Decade|PatentsNum|Diff|\n",
    "|-------|------|----------|----|\n",
    "|AD     |1980  |1         |0   |\n",
    "|AD     |1990  |5         |4   |\n",
    "|AE     |1980  |7         |0   |\n",
    "|AE     |1990  |11        |4   |\n",
    "|AG     |1970  |2         |0   |\n",
    "|AG     |1990  |7         |5   |\n",
    "|AI     |1990  |1         |0   |\n",
    "|AL     |1990  |1         |0   |\n",
    "|AM     |1990  |2         |0   |\n",
    "|AN     |1970  |1         |0   |\n",
    "|AN     |1980  |2         |1   |\n",
    "|AN     |1990  |5         |3   |\n",
    "|AR     |1960  |135       |0   |\n",
    "|AR     |1970  |239       |104 |\n",
    "|AR     |1980  |184       |-55 |\n",
    "|AR     |1990  |292       |108 |\n",
    "\n",
    "**Requirements**\n",
    "\n",
    "- The DataFrame must be sorted by country code and year.\n",
    "- Do **NOT** replace the country code by its whole name.\n",
    "- The output must be saved as a single CSV file, with a header and without any compression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------+----+\n",
      "|PatentNum|country|Year|\n",
      "+---------+-------+----+\n",
      "|  3070801|     BE|1963|\n",
      "|  3070802|     US|1963|\n",
      "|  3070803|     US|1963|\n",
      "|  3070804|     US|1963|\n",
      "|  3070805|     US|1963|\n",
      "+---------+-------+----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "newapatDF.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 192:============================>                            (1 + 1) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+----------+\n",
      "|country|decade|PatentsNum|\n",
      "+-------+------+----------+\n",
      "|     AD|  1980|         1|\n",
      "|     AD|  1990|         5|\n",
      "|     AE|  1980|         7|\n",
      "|     AE|  1990|        11|\n",
      "|     AG|  1970|         2|\n",
      "|     AG|  1990|         7|\n",
      "|     AI|  1990|         1|\n",
      "|     AL|  1990|         1|\n",
      "|     AM|  1990|         2|\n",
      "|     AN|  1970|         1|\n",
      "|     AN|  1980|         2|\n",
      "|     AN|  1990|         5|\n",
      "|     AR|  1960|       135|\n",
      "|     AR|  1970|       239|\n",
      "|     AR|  1980|       184|\n",
      "|     AR|  1990|       292|\n",
      "|     AT|  1960|       950|\n",
      "|     AT|  1970|      2588|\n",
      "|     AT|  1980|      3057|\n",
      "|     AT|  1990|      3665|\n",
      "+-------+------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "grouped_df = newapatDF.groupBy(\"country\", (F.floor((F.col('Year')/10))*10).alias(\"decade\")) # round the year to the nearest decade\n",
    "patents_per_decade_df = grouped_df.agg(F.count(\"*\").alias(\"PatentsNum\"))\n",
    "patents_per_decade_df.orderBy(['country', 'decade']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newapatDF.groupby()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "09091546c7cda573c6363da0c63d2d5e80fd6f34e67ec03a9bc605494bb73032"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
